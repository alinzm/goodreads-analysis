{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-460-de58998dffa6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mauthor_info\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                         \u001b[0mauthor_gender\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthor_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                     \u001b[0mgoodreads_users\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muserid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpub_year\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrating\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor_fan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor_books\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor_hometown\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauthor_gender\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Gathering user groups data from goodreads\n",
    "from urllib.request import urlopen\n",
    "import xml.etree.ElementTree as ET\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "#test_\n",
    "goodreads_users = []\n",
    "not_found = 0\n",
    "found = 0\n",
    "count = 0\n",
    "time_all = 0\n",
    "\n",
    "while count < 5:\n",
    "    start = time.time()\n",
    "    userid = random.randint(19000000,20000000)\n",
    "    \n",
    "    req = Request(\"https://www.goodreads.com/review/list/{}.xml?key=&v=2&shelf=read&per_page=200\".format(userid))\n",
    "    try:\n",
    "        response = urlopen(req)\n",
    "    except URLError as e:\n",
    "        if hasattr(e, 'reason'):\n",
    "            print (\"user \"+str(userid)+\" is not valid\")\n",
    "        elif hasattr(e, 'code'):  \n",
    "            print (\"user \"+str(userid)+\" is not valid\")\n",
    "    else:\n",
    "        count = count +1\n",
    "        for page_numer in range (1,20):\n",
    "            req = Request(\"https://www.goodreads.com/review/list/{}.xml?key=&v=2&shelf=read&per_page=200\".format(userid)+\"&page=\"+str(page_numer))\n",
    "            try:\n",
    "                response = urlopen(req)\n",
    "            except URLError as e:\n",
    "                if hasattr(e, 'reason'):\n",
    "                    print (\"page \"+str(page_numer)+\" is not valid\")\n",
    "                    not_found = not_found +1\n",
    "                elif hasattr(e, 'code'):\n",
    "                    print (\"page \"+str(page_numer)+\" is not valid\")\n",
    "                    not_found = not_found +1\n",
    "            else:\n",
    "                tree = ET.parse(response)\n",
    "                root = tree.getroot()\n",
    "                found = found +1\n",
    "            \n",
    "                for user in root.iter('review'):\n",
    "                    book = user.find('./book/title_without_series').text\n",
    "                    pub_year = user.find('./book/publication_year').text\n",
    "                    rating = user.find('./book/average_rating').text\n",
    "                    author = user.find('./book/authors/author/name').text\n",
    "                    author_id = user.find('./book/authors/author/id').text\n",
    "        \n",
    "                    author_req = Request(\"https://www.goodreads.com/author/show/{}?format=xml&key=\".format(author_id))\n",
    "                    response = urlopen(author_req)\n",
    "                    tree = ET.parse(response)\n",
    "                    root = tree.getroot()\n",
    "                    for author_info in root.iter('fans_count'):\n",
    "                        author_fan = author_info.text\n",
    "                    for author_info in root.iter('works_count'):\n",
    "                        author_books = author_info.text\n",
    "                    for author_info in root.iter('hometown'):\n",
    "                        author_hometown = author_info.text\n",
    "                    for author_info in root.iter('gender'):\n",
    "                        author_gender = author_info.text\n",
    "                    time.sleep(1)       \n",
    "                    goodreads_users.append([userid,book,author,pub_year,rating,author_fan,author_books,author_hometown,author_gender])  \n",
    "                    \n",
    "            goodreads_network = pd.DataFrame(goodreads_users)\n",
    "            with open('/Users/choobani/Desktop/userBooks.csv', 'a') as final_users:\n",
    "                goodreads_network.to_csv(final_users, mode='a',header=False, index=False)         \n",
    "            goodreads_users = []\n",
    "            \n",
    "        time.sleep(1)\n",
    "        end = time.time()\n",
    "        time_all = time_all + (end-start)\n",
    "    \n",
    "    \n",
    "print (str(time_all/60)+\" Minutes to crawl \"+str(count)+\" users\")\n",
    "print (\"From \"+ str(found+not_found)+\" pages \"+str(not_found)+\" Pages are not Found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
